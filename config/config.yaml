dataset_directory: "/ivi/ilps/datasets/baidu_ultr"

bert_config:
  _target_: transformers.BertConfig
  vocab_size: 22_000
  num_hidden_layers: 12
  num_attention_heads: 12
  hidden_size: 768
  do_mlm_task: True
  do_ctr_task: False

training_arguments:
  _target_: transformers.TrainingArguments
  output_dir: "output/"
  report_to: "wandb"
  logging_steps: 100
  evaluation_strategy: "no"
  learning_rate: 0.00005
  max_steps: 500_000
  warmup_steps: 5_000
  weight_decay: 0.01
  max_grad_norm: 1.0
  per_device_train_batch_size: 64
  dataloader_num_workers: 4
  save_total_limit: 4
  seed: 2024

hydra:
  job:
    env_set:
      WANDB_PROJECT: baidu-bert-model
