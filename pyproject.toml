[tool.poetry]
name = "baidu-bert-model"
version = "1.0.0"
description = "Training BERT-based cross-encoders with ULTR loss functions."
authors = ["Romain <romain.deffayet@naverlabs.com>", "Philipp <p.k.hager@uva.nl>"]
license = "MIT"
readme = "README.md"

[tool.poetry.dependencies]

# Main
python = "^3.10"
jaxlib = {version = "0.4.13+cuda12.cudnn89", source = "jax_cuda"}
jax = {version = "0.4.13", extras=["cuda12_pip"]}
flax = "^0.7"
torch = {version = "^2.2", source = "torch_cpu"}
hydra-core = "^1.3"

# Learning
transformers = {version = "4.39", extras=["flax"]}
rax = "^0.3"
scipy = "<1.13"
scikit-learn = "^1.4"

# Misc
wandb = "^0.16"
huggingface-hub = "^0.22"
pandas = "^2.2"

[[tool.poetry.source]]
name = "jax_cuda"
url = "https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
priority = "explicit"

[[tool.poetry.source]]
name = "torch_cpu"
url = "https://download.pytorch.org/whl/cpu"
priority = "explicit"



[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
